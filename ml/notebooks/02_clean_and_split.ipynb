{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "279dfe23-3d97-4660-9532-03049b5d79ad",
   "metadata": {},
   "source": [
    "# 02 — Clean comments and make train/val/test splits\n",
    "\n",
    "We’ll:\n",
    "\n",
    "1. load the raw CSV from step 01,\n",
    "2. lightly clean text + keep **English-only**,\n",
    "3. carry forward the **video-level weak labels** and target distributions,\n",
    "4. split into **train / val / test**,\n",
    "5. save the cleaned and split CSVs for modeling.\n",
    "\n",
    "---\n",
    "\n",
    "## A) Setup & load raw data\n",
    "\n",
    "**What this cell does:** imports, points to files, sets deterministic language detection, and loads `yt_comments_raw.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b33b4d7-8be4-47de-88c5-90141725b6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2406, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>platform</th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>like_count</th>\n",
       "      <th>published_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>source_url</th>\n",
       "      <th>video_label</th>\n",
       "      <th>target_neg</th>\n",
       "      <th>target_neu</th>\n",
       "      <th>target_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>youtube</td>\n",
       "      <td>iV46TJKL8cU</td>\n",
       "      <td>UgwagL2KD03y4uI2XtB4AaABAg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@DrunkMonkey-gx8oy</td>\n",
       "      <td>Disney - “Coming to a theatre near you” Me - I...</td>\n",
       "      <td>97627</td>\n",
       "      <td>2024-12-04T23:15:53Z</td>\n",
       "      <td>2024-12-04T23:15:53Z</td>\n",
       "      <td>https://www.youtube.com/watch?v=iV46TJKL8cU</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>youtube</td>\n",
       "      <td>iV46TJKL8cU</td>\n",
       "      <td>UgyoITtGRyj1j8jx4pt4AaABAg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@MrH1pster</td>\n",
       "      <td>This movie is magical. When I closed the tab, ...</td>\n",
       "      <td>12355</td>\n",
       "      <td>2025-01-25T11:40:17Z</td>\n",
       "      <td>2025-01-27T08:07:31Z</td>\n",
       "      <td>https://www.youtube.com/watch?v=iV46TJKL8cU</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>youtube</td>\n",
       "      <td>iV46TJKL8cU</td>\n",
       "      <td>UgxlVrcG-NT8qt1Z5Bl4AaABAg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@redbearddan2000</td>\n",
       "      <td>I'll give Disney some credit. They are brave e...</td>\n",
       "      <td>187153</td>\n",
       "      <td>2024-12-03T17:52:05Z</td>\n",
       "      <td>2024-12-03T17:52:05Z</td>\n",
       "      <td>https://www.youtube.com/watch?v=iV46TJKL8cU</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  platform     video_id                  comment_id  parent_id  \\\n",
       "0  youtube  iV46TJKL8cU  UgwagL2KD03y4uI2XtB4AaABAg        NaN   \n",
       "1  youtube  iV46TJKL8cU  UgyoITtGRyj1j8jx4pt4AaABAg        NaN   \n",
       "2  youtube  iV46TJKL8cU  UgxlVrcG-NT8qt1Z5Bl4AaABAg        NaN   \n",
       "\n",
       "               author                                               text  \\\n",
       "0  @DrunkMonkey-gx8oy  Disney - “Coming to a theatre near you” Me - I...   \n",
       "1          @MrH1pster  This movie is magical. When I closed the tab, ...   \n",
       "2    @redbearddan2000  I'll give Disney some credit. They are brave e...   \n",
       "\n",
       "   like_count          published_at            updated_at  \\\n",
       "0       97627  2024-12-04T23:15:53Z  2024-12-04T23:15:53Z   \n",
       "1       12355  2025-01-25T11:40:17Z  2025-01-27T08:07:31Z   \n",
       "2      187153  2024-12-03T17:52:05Z  2024-12-03T17:52:05Z   \n",
       "\n",
       "                                    source_url video_label  target_neg  \\\n",
       "0  https://www.youtube.com/watch?v=iV46TJKL8cU    negative         0.8   \n",
       "1  https://www.youtube.com/watch?v=iV46TJKL8cU    negative         0.8   \n",
       "2  https://www.youtube.com/watch?v=iV46TJKL8cU    negative         0.8   \n",
       "\n",
       "   target_neu  target_pos  \n",
       "0        0.15        0.05  \n",
       "1        0.15        0.05  \n",
       "2        0.15        0.05  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langdetect import detect, DetectorFactory, LangDetectException\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# deterministic langdetect\n",
    "DetectorFactory.seed = 42\n",
    "\n",
    "DATA_DIR = Path(\"../data\")\n",
    "RAW_CSV  = DATA_DIR / \"yt_comments_raw.csv\"\n",
    "CLEAN_CSV = DATA_DIR / \"yt_comments_clean.csv\"\n",
    "\n",
    "SENT_TRAIN = DATA_DIR / \"sentiment_train.csv\"\n",
    "SENT_VAL   = DATA_DIR / \"sentiment_val.csv\"\n",
    "SENT_TEST  = DATA_DIR / \"sentiment_test.csv\"\n",
    "\n",
    "df = pd.read_csv(RAW_CSV)\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7041e64-0a97-4ddd-bdea-5c4d6fc8567f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## B) Minimal text cleaning + language check helpers\n",
    "\n",
    "**What this cell does:** removes URLs/extra spaces; defines an `is_english` guard that’s robust to short/odd strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "603321ee-f0ad-4228-8010-f8d80d09e68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_RE   = re.compile(r\"https?://\\S+|www\\.\\S+\")\n",
    "SPACE_RE = re.compile(r\"\\s+\")\n",
    "\n",
    "def clean_text(s: str) -> str:\n",
    "    if not isinstance(s, str):\n",
    "        s = str(s)\n",
    "    s = s.replace(\"\\u200b\", \" \")\n",
    "    s = URL_RE.sub(\" \", s)\n",
    "    s = SPACE_RE.sub(\" \", s)\n",
    "    return s.strip()\n",
    "\n",
    "def is_english(s: str) -> bool:\n",
    "    try:\n",
    "        # quick guard for very short strings\n",
    "        if len(s) < 3:\n",
    "            return False\n",
    "        lang = detect(s)\n",
    "        return lang == \"en\"\n",
    "    except LangDetectException:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9047d4b2-1b06-4069-862d-994f214b058e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## C) Keep top-level comments, clean, and filter to English\n",
    "\n",
    "**What this cell does:**\n",
    "\n",
    "* enforces top-level only (already true from step 01, but we keep it explicit),\n",
    "* deduplicates by `comment_id`,\n",
    "* applies `clean_text`,\n",
    "* filters to English comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbcd610a-7c28-41e7-a5eb-4d7156dd7b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw rows: 2401\n",
      "English rows: 2089\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "video_id\n",
       "iV46TJKL8cU    1119\n",
       "n0OFH4xpPr4     970\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.copy()\n",
    "\n",
    "# keep only top-level\n",
    "df = df[df[\"parent_id\"].isna()].copy()\n",
    "\n",
    "# drop dup comment_id and empty text\n",
    "df[\"text\"] = df[\"text\"].astype(str).map(clean_text)\n",
    "df = df.drop_duplicates(subset=[\"comment_id\"]).reset_index(drop=True)\n",
    "df = df[df[\"text\"].str.len() >= 3].copy()\n",
    "\n",
    "# English filter\n",
    "mask_en = df[\"text\"].map(is_english)\n",
    "df_en = df[mask_en].reset_index(drop=True)\n",
    "\n",
    "print(\"Raw rows:\", len(df))\n",
    "print(\"English rows:\", len(df_en))\n",
    "df_en[\"video_id\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb5b70c-c791-4c29-a71f-1b098deac0ac",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## D) Preserve weak labels & targets; prepare training columns\n",
    "\n",
    "**What this cell does:**\n",
    "\n",
    "* ensures `video_label` is present,\n",
    "* carries forward `target_neg/neu/pos`, with sensible defaults if missing,\n",
    "* creates the final columns used for training (including `sentiment` = `video_label`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7e8be90-6e98-47b2-88c3-e2b65c7f61c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>video_id</th>\n",
       "      <th>target_neg</th>\n",
       "      <th>target_neu</th>\n",
       "      <th>target_pos</th>\n",
       "      <th>like_count</th>\n",
       "      <th>source_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Disney - “Coming to a theatre near you” Me - I...</td>\n",
       "      <td>negative</td>\n",
       "      <td>iV46TJKL8cU</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.05</td>\n",
       "      <td>97627</td>\n",
       "      <td>https://www.youtube.com/watch?v=iV46TJKL8cU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This movie is magical. When I closed the tab, ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>iV46TJKL8cU</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.05</td>\n",
       "      <td>12355</td>\n",
       "      <td>https://www.youtube.com/watch?v=iV46TJKL8cU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'll give Disney some credit. They are brave e...</td>\n",
       "      <td>negative</td>\n",
       "      <td>iV46TJKL8cU</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.05</td>\n",
       "      <td>187153</td>\n",
       "      <td>https://www.youtube.com/watch?v=iV46TJKL8cU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I finally found it. The one video I will never...</td>\n",
       "      <td>negative</td>\n",
       "      <td>iV46TJKL8cU</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.05</td>\n",
       "      <td>577</td>\n",
       "      <td>https://www.youtube.com/watch?v=iV46TJKL8cU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If i saw this movie on a plane. I would still ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>iV46TJKL8cU</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.05</td>\n",
       "      <td>161137</td>\n",
       "      <td>https://www.youtube.com/watch?v=iV46TJKL8cU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment     video_id  \\\n",
       "0  Disney - “Coming to a theatre near you” Me - I...  negative  iV46TJKL8cU   \n",
       "1  This movie is magical. When I closed the tab, ...  negative  iV46TJKL8cU   \n",
       "2  I'll give Disney some credit. They are brave e...  negative  iV46TJKL8cU   \n",
       "3  I finally found it. The one video I will never...  negative  iV46TJKL8cU   \n",
       "4  If i saw this movie on a plane. I would still ...  negative  iV46TJKL8cU   \n",
       "\n",
       "   target_neg  target_neu  target_pos  like_count  \\\n",
       "0         0.8        0.15        0.05       97627   \n",
       "1         0.8        0.15        0.05       12355   \n",
       "2         0.8        0.15        0.05      187153   \n",
       "3         0.8        0.15        0.05         577   \n",
       "4         0.8        0.15        0.05      161137   \n",
       "\n",
       "                                    source_url  \n",
       "0  https://www.youtube.com/watch?v=iV46TJKL8cU  \n",
       "1  https://www.youtube.com/watch?v=iV46TJKL8cU  \n",
       "2  https://www.youtube.com/watch?v=iV46TJKL8cU  \n",
       "3  https://www.youtube.com/watch?v=iV46TJKL8cU  \n",
       "4  https://www.youtube.com/watch?v=iV46TJKL8cU  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure expected columns exist (from step 01)\n",
    "if \"video_label\" not in df_en.columns:\n",
    "    raise ValueError(\"video_label column missing. Re-run 01_fetch_youtube_comments to include video-level labels.\")\n",
    "\n",
    "# Keep only necessary columns for sentiment training + helpful metadata\n",
    "keep_cols = [\n",
    "    \"text\",\"video_id\",\"video_label\",\"like_count\",\"source_url\",\n",
    "    \"target_neg\",\"target_neu\",\"target_pos\"\n",
    "]\n",
    "# Some columns may be missing target_* if you didn’t add them in step 01; fill sensible defaults by video_label\n",
    "df_en = df_en.reindex(columns=[c for c in keep_cols if c in df_en.columns])\n",
    "\n",
    "if not set([\"target_neg\",\"target_neu\",\"target_pos\"]).issubset(df_en.columns):\n",
    "    # default targets by video_label\n",
    "    def default_target(vlab):\n",
    "        if vlab == \"negative\":\n",
    "            return pd.Series([0.80,0.15,0.05], index=[\"target_neg\",\"target_neu\",\"target_pos\"])\n",
    "        if vlab == \"positive\":\n",
    "            return pd.Series([0.05,0.15,0.80], index=[\"target_neg\",\"target_neu\",\"target_pos\"])\n",
    "        return pd.Series([0.20,0.60,0.20], index=[\"target_neg\",\"target_neu\",\"target_pos\"])\n",
    "    targets = df_en[\"video_label\"].map(default_target)\n",
    "    df_en = pd.concat([df_en.drop(columns=[\"target_neg\",\"target_neu\",\"target_pos\"], errors=\"ignore\"), targets], axis=1)\n",
    "\n",
    "# Map weak label to the 'sentiment' column expected by the training notebook\n",
    "df_en[\"sentiment\"] = df_en[\"video_label\"].astype(str)\n",
    "df_en = df_en[[\"text\",\"sentiment\",\"video_id\",\"target_neg\",\"target_neu\",\"target_pos\",\"like_count\",\"source_url\"]]\n",
    "\n",
    "df_en.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3aac18-e675-4f5d-8a31-52069df61698",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## E) Split into train / val / test (video-aware when possible)\n",
    "\n",
    "**What this cell does:**\n",
    "\n",
    "* If we have **≥3 videos**, we split **by video_id** (prevents leakage).\n",
    "* If fewer (your current case), we do **comment-level stratified** splits so you can keep moving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e248e7b2-745f-4065-addc-b75ccc2f511d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (1462, 8) label counts:\n",
      " sentiment\n",
      "negative    783\n",
      "positive    679\n",
      "Name: count, dtype: int64\n",
      "val (313, 8) label counts:\n",
      " sentiment\n",
      "negative    168\n",
      "positive    145\n",
      "Name: count, dtype: int64\n",
      "test (314, 8) label counts:\n",
      " sentiment\n",
      "negative    168\n",
      "positive    146\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "rng = 42\n",
    "vids = df_en[\"video_id\"].unique().tolist()\n",
    "\n",
    "def split_by_video(frame: pd.DataFrame, train_p=0.7, val_p=0.15, test_p=0.15):\n",
    "    # split on unique video ids\n",
    "    vids = frame[\"video_id\"].unique()\n",
    "    n = len(vids)\n",
    "    if n >= 3:\n",
    "        # 70/15/15 by video\n",
    "        vid_train, vid_tmp = train_test_split(vids, test_size=(1-train_p), random_state=rng)\n",
    "        rel = val_p / (val_p + test_p)\n",
    "        vid_val, vid_test = train_test_split(vid_tmp, test_size=(1-rel), random_state=rng)\n",
    "        return (\n",
    "            frame[frame.video_id.isin(vid_train)].reset_index(drop=True),\n",
    "            frame[frame.video_id.isin(vid_val)].reset_index(drop=True),\n",
    "            frame[frame.video_id.isin(vid_test)].reset_index(drop=True),\n",
    "        )\n",
    "    else:\n",
    "        # Fallback: comment-level splits (keeps your project moving with 2 videos)\n",
    "        tr, tmp = train_test_split(frame, test_size=0.3, random_state=rng, stratify=frame[\"sentiment\"])\n",
    "        va, te = train_test_split(tmp, test_size=0.5, random_state=rng, stratify=tmp[\"sentiment\"])\n",
    "        return tr.reset_index(drop=True), va.reset_index(drop=True), te.reset_index(drop=True)\n",
    "\n",
    "tr_df, va_df, te_df = split_by_video(df_en)\n",
    "\n",
    "for name, part in [(\"train\",tr_df),(\"val\",va_df),(\"test\",te_df)]:\n",
    "    print(name, part.shape, \"label counts:\\n\", part[\"sentiment\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24daf572-dee0-4a20-af55-9ef1b1e96708",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## F) Save cleaned data + splits\n",
    "\n",
    "**What this cell does:** writes the cleaned English-only data and the three splits to disk for the fine-tuning notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "703b896e-fc74-4379-82a1-00b7e6b997fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(WindowsPath('../data/yt_comments_clean.csv'),\n",
       " WindowsPath('../data/sentiment_train.csv'),\n",
       " WindowsPath('../data/sentiment_val.csv'),\n",
       " WindowsPath('../data/sentiment_test.csv'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save cleaned all-English comments (for inspection)\n",
    "df_en.to_csv(CLEAN_CSV, index=False, encoding=\"utf-8\")\n",
    "\n",
    "# Save splits for sentiment training notebook (expects 'text' + 'sentiment')\n",
    "tr_df.to_csv(SENT_TRAIN, index=False, encoding=\"utf-8\")\n",
    "va_df.to_csv(SENT_VAL,   index=False, encoding=\"utf-8\")\n",
    "te_df.to_csv(SENT_TEST,  index=False, encoding=\"utf-8\")\n",
    "\n",
    "CLEAN_CSV, SENT_TRAIN, SENT_VAL, SENT_TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d08218-10eb-414f-b3d8-cb758a6056ca",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ✅ Wrap-up: What we just did (02_clean_and_split)\n",
    "\n",
    "**TL;DR:** We took the raw comments, cleaned them up, filtered to **English**, carried forward your **video-level weak labels** and targets, split into train/val/test, and saved everything for model training.\n",
    "\n",
    "* **Cleaned file:** `ml/data/yt_comments_clean.csv`\n",
    "* **Splits for training:**\n",
    "  * `ml/data/sentiment_train.csv`\n",
    "  * `ml/data/sentiment_val.csv`\n",
    "  * `ml/data/sentiment_test.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ee376c-8e0f-475f-b4a7-26a1e2a938e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yt-comment-venv",
   "language": "python",
   "name": "yt-comment-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
