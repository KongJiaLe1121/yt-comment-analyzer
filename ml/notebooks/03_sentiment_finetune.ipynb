{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "206979c9-84e1-4087-8d55-0695d22771fe",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# 03 â€” Fine-tune sentiment model (weak supervision + bag regularizer)\n",
    "\n",
    "Weâ€™ll fine-tune `distilbert-base-uncased` on your **English YouTube comments**, using:\n",
    "\n",
    "* **Weak labels** from the video â€œvibeâ€ (negative/positive), and\n",
    "* A **bag-level KL term** that nudges the *average* comment sentiment per video toward the video-level target.\n",
    "\n",
    "Outputs are saved to `models/sentiment_en/` for your Streamlit app.\n",
    "\n",
    "---\n",
    "\n",
    "## A) Setup & load splits\n",
    "\n",
    "> Loads train/val/test from step **02** and shows class counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "653a995e-d9cd-4c51-9ab2-87153f841d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers: 4.55.2\n",
      "train sentiment\n",
      "negative    783\n",
      "positive    679\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "val sentiment\n",
      "negative    168\n",
      "positive    145\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "test sentiment\n",
      "negative    168\n",
      "positive    146\n",
      "Name: count, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imports & paths\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch, torch.nn as nn\n",
    "import transformers, evaluate, sklearn\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "print(\"transformers:\", transformers.__version__)\n",
    "DATA_DIR = Path(\"../data\")\n",
    "OUT_DIR  = Path(\"../..\") / \"models\" / \"sentiment_en\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load data\n",
    "df_tr = pd.read_csv(DATA_DIR / \"sentiment_train.csv\")\n",
    "df_va = pd.read_csv(DATA_DIR / \"sentiment_val.csv\")\n",
    "df_te = pd.read_csv(DATA_DIR / \"sentiment_test.csv\")\n",
    "\n",
    "for name, df in [(\"train\", df_tr), (\"val\", df_va), (\"test\", df_te)]:\n",
    "    print(name, df[\"sentiment\"].value_counts(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86f198f-7418-4614-8afd-0e45115e5a55",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## B) Prep: labels, per-video IDs, weak targets\n",
    "\n",
    "> Collapses 3-way targets (neg/neu/pos) into **binary** (neg/pos) proportions; assigns a stable `vid` per `video_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2c8b47d-cf52-44d7-8d8a-e508c31c30cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>video_id</th>\n",
       "      <th>target_neg</th>\n",
       "      <th>target_neu</th>\n",
       "      <th>target_pos</th>\n",
       "      <th>like_count</th>\n",
       "      <th>source_url</th>\n",
       "      <th>labels</th>\n",
       "      <th>vid</th>\n",
       "      <th>t_neg</th>\n",
       "      <th>t_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Boring this new snow white ruin Disney instead...</td>\n",
       "      <td>negative</td>\n",
       "      <td>iV46TJKL8cU</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.youtube.com/watch?v=iV46TJKL8cU</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The September 11th attacks have been forgotten...</td>\n",
       "      <td>negative</td>\n",
       "      <td>iV46TJKL8cU</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.youtube.com/watch?v=iV46TJKL8cU</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>She is jealous i think... i wish i can watch i...</td>\n",
       "      <td>positive</td>\n",
       "      <td>n0OFH4xpPr4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.youtube.com/watch?v=n0OFH4xpPr4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.941176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment     video_id  \\\n",
       "0  Boring this new snow white ruin Disney instead...  negative  iV46TJKL8cU   \n",
       "1  The September 11th attacks have been forgotten...  negative  iV46TJKL8cU   \n",
       "2  She is jealous i think... i wish i can watch i...  positive  n0OFH4xpPr4   \n",
       "\n",
       "   target_neg  target_neu  target_pos  like_count  \\\n",
       "0        0.80        0.15        0.05           0   \n",
       "1        0.80        0.15        0.05           1   \n",
       "2        0.05        0.15        0.80           0   \n",
       "\n",
       "                                    source_url  labels  vid     t_neg  \\\n",
       "0  https://www.youtube.com/watch?v=iV46TJKL8cU       0    0  0.941176   \n",
       "1  https://www.youtube.com/watch?v=iV46TJKL8cU       0    0  0.941176   \n",
       "2  https://www.youtube.com/watch?v=n0OFH4xpPr4       1    1  0.058824   \n",
       "\n",
       "      t_pos  \n",
       "0  0.058824  \n",
       "1  0.058824  \n",
       "2  0.941176  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label maps\n",
    "label2id = {\"negative\":0, \"positive\":1}\n",
    "id2label = {v:k for k,v in label2id.items()}\n",
    "\n",
    "# Collapse targets to 2D (neg,pos)\n",
    "def to_2d_target(row):\n",
    "    tn = float(row.get(\"target_neg\", 0.0))\n",
    "    tp = float(row.get(\"target_pos\", 0.0))\n",
    "    s = tn + tp\n",
    "    if s <= 0:\n",
    "        return pd.Series([0.5, 0.5], index=[\"t_neg\",\"t_pos\"])\n",
    "    return pd.Series([tn/s, tp/s], index=[\"t_neg\",\"t_pos\"])\n",
    "\n",
    "# Prepare dataframes\n",
    "def prep(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[\"labels\"] = df[\"sentiment\"].map(label2id).astype(int)\n",
    "    # stable int IDs for videos\n",
    "    vid_map = {v:i for i,v in enumerate(df[\"video_id\"].astype(str).unique())}\n",
    "    df[\"vid\"] = df[\"video_id\"].astype(str).map(vid_map).astype(int)\n",
    "    # 2-d per-row target (weak supervision)\n",
    "    df[[\"t_neg\",\"t_pos\"]] = df.apply(to_2d_target, axis=1)\n",
    "    return df\n",
    "\n",
    "df_tr = prep(df_tr)\n",
    "df_va = prep(df_va)\n",
    "df_te = prep(df_te)\n",
    "\n",
    "df_tr.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe0945b-64a5-41a2-a8c3-e82d568ed8d1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## C) Tokenize & build HF datasets\n",
    "\n",
    "> Keeps custom fields (`vid`, `tgt2`) for the custom loss; weâ€™ll tensorize them in a custom collator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc4f804f-0029-48a1-8bc0-2f1a30e93c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a158a0e53f8a479291dcf4e0f6c042af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1462 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "877f9729c5424875a7e306dfd0b61ac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/313 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb50cbb4b80447f2932d459e777d14e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/314 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1462, 313, 314)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenizer\n",
    "MODEL = \"distilbert-base-uncased\"\n",
    "tok = AutoTokenizer.from_pretrained(MODEL)\n",
    "max_len = 160\n",
    "\n",
    "# Tokenize + carry extras\n",
    "def tok_fn(batch):\n",
    "    enc = tok(batch[\"text\"], truncation=True, padding=\"max_length\", max_length=max_len)\n",
    "    enc[\"labels\"] = batch[\"labels\"]\n",
    "    enc[\"vid\"]    = batch[\"vid\"]\n",
    "    # ensure list-of-lists, not tuples â†’ safer tensorization\n",
    "    enc[\"tgt2\"]   = [[float(a), float(b)] for a, b in zip(batch[\"t_neg\"], batch[\"t_pos\"])]\n",
    "    return enc\n",
    "\n",
    "# Build datasets\n",
    "ds = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(df_tr[[\"text\",\"labels\",\"vid\",\"t_neg\",\"t_pos\"]]),\n",
    "    \"val\":   Dataset.from_pandas(df_va[[\"text\",\"labels\",\"vid\",\"t_neg\",\"t_pos\"]]),\n",
    "    \"test\":  Dataset.from_pandas(df_te[[\"text\",\"labels\",\"vid\",\"t_neg\",\"t_pos\"]]),\n",
    "}).map(tok_fn, batched=True, remove_columns=[\"text\",\"t_neg\",\"t_pos\"])\n",
    "\n",
    "# Leave as python lists; our collator will create tensors (and preserve extras)\n",
    "for split in ds:\n",
    "    ds[split].set_format(type=None)\n",
    "\n",
    "len(ds[\"train\"]), len(ds[\"val\"]), len(ds[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83ed8d3-31a1-4723-8aa9-97b0e8f6962b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## D) Model, class weights, and custom Trainer (bag-level KL)\n",
    "\n",
    "> The loss = **CE on weak labels** + **Î² Â· KL(avg_pred_per_video || target_per_video)** within each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c13797a-3c52-4a80-91ee-a829e10c3c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Class weights for noisy labels\n",
    "y = df_tr[\"labels\"].values\n",
    "classes = np.array([0,1])\n",
    "cw = compute_class_weight(class_weight=\"balanced\", classes=classes, y=y)\n",
    "class_weights = torch.tensor(cw, dtype=torch.float)\n",
    "\n",
    "# Base model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL, num_labels=2, id2label=id2label, label2id=label2id\n",
    ")\n",
    "\n",
    "# Custom Trainer with bag-level KL\n",
    "class BagKLBinaryTrainer(Trainer):\n",
    "    def __init__(self, *args, beta=0.5, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.beta = beta\n",
    "        self.ce = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        # custom fields (preserved via our collator)\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        vids   = inputs.pop(\"vid\")\n",
    "        tgt2   = inputs.pop(\"tgt2\")  # [B,2] float tensor\n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        logits  = outputs.logits\n",
    "        probs   = torch.softmax(logits, dim=-1)\n",
    "\n",
    "        # (1) CE on weak labels\n",
    "        loss_ce = self.ce(logits, labels)\n",
    "\n",
    "        # (2) Bag-level KL per video in-batch\n",
    "        kl = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "        loss_agg = logits.new_tensor(0.0)\n",
    "        uniq = torch.unique(vids)\n",
    "        for v in uniq:\n",
    "            m = (vids == v)\n",
    "            if m.sum() == 0:\n",
    "                continue\n",
    "            avg_pred = probs[m].mean(dim=0).clamp(1e-6, 1.0)\n",
    "            avg_tgt  = tgt2[m].mean(dim=0).clamp(1e-6, 1.0)\n",
    "            loss_agg = loss_agg + kl(torch.log(avg_pred), avg_tgt)\n",
    "\n",
    "        loss = loss_ce + self.beta * loss_agg\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6135fa13-0c97-406f-8102-23325b9c1b51",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## E) Metrics, collator, training args, trainer\n",
    "\n",
    "> The **custom collator** pads token fields and re-attaches `vid`/`tgt2`.\n",
    "> `remove_unused_columns=False` is crucial so Trainer wonâ€™t drop our extras.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "877e6c83-7af5-46af-80d3-2769a2bef572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch keys: ['input_ids', 'attention_mask', 'labels', 'vid', 'tgt2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kongj\\AppData\\Local\\Temp\\ipykernel_21104\\386921117.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `BagKLBinaryTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "metric_acc = evaluate.load(\"accuracy\")\n",
    "metric_f1  = evaluate.load(\"f1\")\n",
    "metric_pr  = evaluate.load(\"precision\")\n",
    "metric_rc  = evaluate.load(\"recall\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    logits = p.predictions[0] if isinstance(p.predictions, (tuple, list)) else p.predictions\n",
    "    y_pred = logits.argmax(-1)\n",
    "    y_true = p.label_ids\n",
    "    return {\n",
    "        \"acc\":  metric_acc.compute(predictions=y_pred, references=y_true)[\"accuracy\"],\n",
    "        \"f1\":   metric_f1.compute(predictions=y_pred, references=y_true, average=\"binary\")[\"f1\"],\n",
    "        \"prec\": metric_pr.compute(predictions=y_pred, references=y_true, average=\"binary\")[\"precision\"],\n",
    "        \"rec\":  metric_rc.compute(predictions=y_pred, references=y_true, average=\"binary\")[\"recall\"],\n",
    "    }\n",
    "\n",
    "# Custom collator (preserves extras)\n",
    "from transformers import DataCollatorWithPadding\n",
    "_pad = DataCollatorWithPadding(tokenizer=tok)\n",
    "\n",
    "def collate_with_extras(features):\n",
    "    # token fields to pad\n",
    "    token_keys = [\"input_ids\", \"attention_mask\"]\n",
    "    if \"token_type_ids\" in features[0]:\n",
    "        token_keys.append(\"token_type_ids\")\n",
    "\n",
    "    # split tokenizable vs. extras\n",
    "    tok_feats = [{k: f[k] for k in token_keys if k in f} | {\"labels\": f[\"labels\"]} for f in features]\n",
    "    batch = _pad(tok_feats)\n",
    "\n",
    "    # add our extras as tensors\n",
    "    if \"vid\" in features[0]:\n",
    "        batch[\"vid\"]  = torch.tensor([f[\"vid\"] for f in features], dtype=torch.long)\n",
    "    if \"tgt2\" in features[0]:\n",
    "        batch[\"tgt2\"] = torch.tensor([f[\"tgt2\"] for f in features], dtype=torch.float)\n",
    "    return batch\n",
    "\n",
    "# TrainingArguments & Trainer\n",
    "args = TrainingArguments(\n",
    "    output_dir=str(OUT_DIR / \"ckpt\"),\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    dataloader_pin_memory=False,\n",
    "    report_to=\"none\",\n",
    "    remove_unused_columns=False,   # ðŸ”‘ keep 'vid' and 'tgt2'\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "trainer = BagKLBinaryTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    eval_dataset=ds[\"val\"],\n",
    "    data_collator=collate_with_extras,  # ðŸ”‘ preserves vid/tgt2\n",
    "    tokenizer=tok,                      # ok to include; collator handles extras\n",
    "    compute_metrics=compute_metrics,\n",
    "    beta=0.5,\n",
    ")\n",
    "\n",
    "# Optional quick sanity check:\n",
    "b = next(iter(trainer.get_train_dataloader()))\n",
    "print(\"Batch keys:\", list(b.keys()))  # expect: input_ids, attention_mask, labels, vid, tgt2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff10f84-7eb1-40d0-b6b0-cfff372ef3c6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## F) Train â†’ Eval â†’ Save\n",
    "\n",
    "> Saves model + tokenizer into `models/sentiment_en/` so your Streamlit app can load it directly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dc04d3c-bd59-45fe-b48d-c1fc7137c5de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='276' max='276' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [276/276 12:53, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.757200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.428000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.283800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.206300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.146800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:22]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL: {'eval_loss': 0.3150944709777832, 'eval_acc': 0.8785942492012779, 'eval_f1': 0.8689655172413793, 'eval_prec': 0.8689655172413793, 'eval_rec': 0.8689655172413793, 'eval_runtime': 12.7348, 'eval_samples_per_second': 24.578, 'eval_steps_per_second': 0.393, 'epoch': 3.0}\n",
      "TEST: {'eval_loss': 0.3868599832057953, 'eval_acc': 0.8598726114649682, 'eval_f1': 0.8523489932885906, 'eval_prec': 0.8355263157894737, 'eval_rec': 0.8698630136986302, 'eval_runtime': 12.5844, 'eval_samples_per_second': 24.951, 'eval_steps_per_second': 0.397, 'epoch': 3.0}\n",
      "Saved to: ..\\..\\models\\sentiment_en\n"
     ]
    }
   ],
   "source": [
    "# Train & evaluate\n",
    "trainer.train()\n",
    "\n",
    "print(\"VAL:\", trainer.evaluate(ds[\"val\"]))\n",
    "print(\"TEST:\", trainer.evaluate(ds[\"test\"]))\n",
    "\n",
    "# Save model & tokenizer\n",
    "trainer.save_model(str(OUT_DIR))\n",
    "tok.save_pretrained(str(OUT_DIR))\n",
    "print(\"Saved to:\", OUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193ae81d-d386-4928-ab53-4ea34794b4f7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## G) Quick inference helper (local sanity test)\n",
    "\n",
    "> Handy for spot-checking outputs before wiring into the app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "996bd42c-a095-4252-a85b-c7af3d0d547b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentEN:\n",
    "    def __init__(self, path=\"../../models/sentiment_en\"):\n",
    "        self.tok = AutoTokenizer.from_pretrained(path)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(path).eval()\n",
    "        self.id2label = self.model.config.id2label\n",
    "\n",
    "    def __call__(self, texts):\n",
    "        enc = self.tok(texts, return_tensors=\"pt\", truncation=True, padding=True, max_length=160)\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(**enc).logits\n",
    "        probs = torch.softmax(logits, dim=-1).cpu().numpy()\n",
    "        labels = [self.id2label[int(i)] for i in probs.argmax(-1)]\n",
    "        return labels, probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11584de0-2ff8-4bc4-bd35-cf9548627e89",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ… Wrap-up: What we just did (03_sentiment_finetune)\n",
    "\n",
    "**TL;DR:** We fine-tuned DistilBERT on your YouTube comments with weak labels, plus a **bag-level KL** that aligns the average comment sentiment per video with the videoâ€™s overall vibe. Then we saved the model to plug straight into your Streamlit app.\n",
    "\n",
    "**Highlights**\n",
    "\n",
    "* Weak labels (neg/pos) from video-level tags\n",
    "* **Class balancing** + **bag-level regularization (Î²=0.5)**\n",
    "* Reproducible splits & seed\n",
    "* Saved to: `models/sentiment_en/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c131b9eb-0a5e-4fe9-ad47-9fdae5bf7294",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yt-comment-venv",
   "language": "python",
   "name": "ig-comment-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
